# Restored baseline training script (based on 41c5563) + modernized output
# åªä¿ç•™ï¼šç°¡åŒ–é…ç½® / logger / éšæ®µåˆ—å°ï¼›ä¸å¼•å…¥æ–°åŠŸèƒ½ (supervision, scheduler, AdamW ç­‰)
import os
import argparse
import torch
import torch.distributed as dist
import time
import cavity_data as cavity
import pinn_solver as psolver
from config import ConfigManager
from logger import get_logger


def parse_args():
    parser = argparse.ArgumentParser(description='Restored NSFnet Training')
    parser.add_argument('--config', type=str, default='configs/production.yaml', help='YAML config file path')
    parser.add_argument('--dry-run', action='store_true', help='Print config & stages then exit')
    return parser.parse_args()


def setup_distributed():
    """Initialize distributed training (ä¿æŒèˆŠç‰ˆèªæ„, å¢åŠ æ›´å‹å¥½è¼¸å‡º)."""
    if 'WORLD_SIZE' not in os.environ or int(os.environ.get('WORLD_SIZE', '1')) <= 1:
        print('ğŸ’» å–®GPUæ¨¡å¼ (æœªæª¢æ¸¬åˆ°åˆ†å¸ƒå¼ç’°å¢ƒè®Šæ•¸)')
        return False
    required_env = ['RANK', 'LOCAL_RANK', 'WORLD_SIZE', 'MASTER_ADDR', 'MASTER_PORT']
    for env_var in required_env:
        if env_var not in os.environ:
            print(f"ç¼ºå°‘ç’°å¢ƒè®Šæ•¸: {env_var} -> å›é€€å–®GPU")
            return False
    try:
        dist.init_process_group(backend='nccl')
        rank = dist.get_rank()
        world_size = dist.get_world_size()
        local_rank = int(os.environ['LOCAL_RANK'])
        torch.cuda.set_device(local_rank)
        if rank == 0:
            print(f"ğŸ“¡ åˆ†å¸ƒå¼å•Ÿå‹•: world={world_size}, rank={rank}, local_rank={local_rank}")
        return True
    except Exception as e:
        print(f"åˆ†å¸ƒå¼åˆå§‹åŒ–å¤±æ•—: {e}; å›é€€å–®GPU")
        return False


def cleanup_distributed():
    if dist.is_initialized():
        dist.destroy_process_group()


def print_stage_table(stages, logger):
    logger.info("=== Training Stages ===")
    for i, st in enumerate(stages, 1):
        logger.info(f"{i:02d} | {st.name:<8} | alpha={st.alpha:.3g} | epochs={st.epochs:,} | lr={st.lr:.2e}")
    logger.info('='*60)


def build_pinn(cfg):
    return psolver.PysicsInformedNeuralNetwork(
        Re=cfg.physics.Re,
        layers=cfg.network.layers,
        layers_1=cfg.network.layers_1,
        hidden_size=cfg.network.hidden_size,
        hidden_size_1=cfg.network.hidden_size_1,
        N_f=cfg.training.N_f,
        alpha_evm=cfg.physics.alpha_evm,
        bc_weight=cfg.physics.bc_weight,
        eq_weight=cfg.physics.eq_weight,
        checkpoint_path='./checkpoint/'
    )


def main():
    args = parse_args()

    # è®€å–é…ç½® (è‹¥æª”æ¡ˆä¸å­˜åœ¨ä½¿ç”¨é è¨­)
    if not os.path.exists(args.config):
        print(f"âš ï¸ æ‰¾ä¸åˆ°é…ç½®æª” {args.config}ï¼Œä½¿ç”¨å…§å»ºé è¨­å€¼")
        config_manager = ConfigManager()
    else:
        config_manager = ConfigManager.from_file(args.config)
    cfg = config_manager.config

    is_distributed = setup_distributed()
    if not is_distributed:
        # è¨­ç½®å–® GPU ç’°å¢ƒè®Šæ•¸ä»¥èˆ‡ solver å°é½Š
        os.environ['RANK'] = '0'; os.environ['LOCAL_RANK'] = '0'; os.environ['WORLD_SIZE'] = '1'

    rank = int(os.environ.get('RANK', 0))
    logger = get_logger(cfg.experiment_name, rank=rank)

    if rank == 0:
        logger.header('Experiment Configuration')
        config_manager.print_config()

    stages = cfg.training.training_stages
    if rank == 0:
        print_stage_table(stages, logger)
    if args.dry_run:
        if rank == 0:
            logger.info('Dry-run çµæŸ (æœªé€²è¡Œè¨“ç·´)')
        return

    # æ§‹å»º PINN
    if rank == 0:
        logger.header('Construct PINN')
    PINN = build_pinn(cfg)
    # logging controls
    PINN.log_interval = cfg.training.log_interval
    PINN.progress_bar_width = 30

    # æ•¸æ“šè¼‰å…¥ (ä¿æŒèˆŠç‰ˆèªæ„: datasets/)
    path = './datasets/'
    dataloader = cavity.DataLoader(path=path, N_f=cfg.training.N_f, N_b=1000)

    # é‚Šç•Œ / æ–¹ç¨‹é»
    boundary_data = dataloader.loading_boundary_data()
    PINN.set_boundary_data(X=boundary_data)
    training_data = dataloader.loading_training_data()
    PINN.set_eq_training_data(X=training_data)

    eval_file = f'./NSFnet/ev-NSFnet/data/cavity_Re{cfg.physics.Re}_256_Uniform.mat'
    x_star, y_star, u_star, v_star, p_star = dataloader.loading_evaluate_data(eval_file)

    total_epochs = sum(st.epochs for st in stages)
    if rank == 0:
        logger.info(f'ğŸš€ é–‹å§‹è¨“ç·´ï¼šç¸½ epochs={total_epochs:,} (stages={len(stages)})')

    try:
        for st in stages:
            if rank == 0:
                logger.stage(st.name, st.alpha, st.epochs, st.lr)
            PINN.current_stage = st.name
            PINN.set_alpha_evm(st.alpha)
            PINN.train(num_epoch=st.epochs, lr=st.lr)
            if rank == 0:
                PINN.evaluate(x_star, y_star, u_star, v_star, p_star)
        if rank == 0:
            logger.header('Training Completed')
    except Exception as e:
        if rank == 0:
            logger.error(f'è¨“ç·´å¤±æ•—: {e}')
        raise
    finally:
        cleanup_distributed()
        if rank == 0:
            logger.close()


if __name__ == '__main__':
    main()
